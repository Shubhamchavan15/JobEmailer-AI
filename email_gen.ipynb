from langchain_groq import ChatGroq
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
import pandas as pd
import uuid
import chromadb

# Initialize the LLM (replace '#' with your actual API key)
llm = ChatGroq(
    temperature=0, 
    groq_api_key='YOUR_GROQ_API_KEY', # Replace with your actual GROQ API key
    model_name="llama-3.1-70b-versatile"
)

# Example usage of LLM (not directly related to the main task but kept for context)
# response = llm.invoke("The first person to land on moon was ...")
# print(response.content)

# Load data from the Nike jobs website
loader = WebBaseLoader("https://jobs.nike.com/job/R-40715?from=job%20search%20funnel")
page_data = loader.load().pop().page_content
# print(page_data) # Uncomment to see the scraped content

# Define prompt for extracting job details
prompt_extract = PromptTemplate.from_template(
    """
    ### SCRAPED TEXT FROM WEBSITE:
    {page_data}
    ### INSTRUCTION:
    The scraped text is from the career's page of a website.
    Your job is to extract the job postings and return them in JSON format containing the 
    following keys: `role`, `experience`, `skills` and `description`.
    Only return the valid JSON.
    ### VALID JSON (NO PREAMBLE):    
    """
)

# Create a chain for extraction
chain_extract = prompt_extract | llm 
res = chain_extract.invoke(input={'page_data':page_data})
# print(type(res.content)) # Uncomment to see the type of the response content

# Parse the JSON response
json_parser=JsonOutputParser()
job=json_parser.parse(res.content)
# print(json_res) # Uncomment to see the parsed job details
# print(type(json_res)) # Uncomment to see the type of the parsed job details

# Load your certificates data
try:
    df=pd.read_csv("My_Certificates_Links.csv")
except FileNotFoundError:
    print("Error: My_Certificates_Links.csv not found. Please ensure the file is in the correct directory.")
    # Create a dummy DataFrame for demonstration if the file is not found
    df = pd.DataFrame({
        'Techstack': ['DBMS Certification', 'Scalar Operating System'],
        'Links': [
            'https://olympus.mygreatlearning.com/courses/64941/certificate?pb_id=581',
            'https://moonshot.scaler.com/s/sl/ARcO02Xi5u?_gl=1*xpac2a*_gcl_au*ODEzMjkzMjAzLjE3NDQ3OTcwMzkuMjA5OTQ3ODY4Ny4xNzQ3NzQ5MjA0LjE3NDc3NDkyMDM.*FPAU*ODEzMjkzMjAzLjE3NDQ3OTcwMzkuMTEwOTkyMDI3NC4xNzQ0Nzk3MDQ0LjE3NDQ3OTcwNDQ.*_ga*MTgzMjYwOTIzOC4xNzIzMDUxMTI1*_ga_53S71ZZG1X*czE3NDc3NDkyMDMkbzckZzEkdDE3NDc3NDk0MDYkajAkbDAkaDEwMzEzMTAxODMkZG5iZjZXUVB4UlZtWmJ1SXc2aVByRGZLbjAwYjM0OWxXQ0E.'
        ]
    })
# print(df) # Uncomment to see your certificates DataFrame

# Initialize ChromaDB client and collection
client = chromadb.PersistentClient('vectorstore')
collection = client.get_or_create_collection(name="portfolio")

# Add documents to the collection if it's empty
if not collection.count():
    for _, row in df.iterrows():
        collection.add(documents=row["Techstack"],
                       metadatas={"links": row["Links"]},
                       ids=[str(uuid.uuid4())])

# Query the collection for relevant links based on job skills
# Ensure job['skills'] is a list of strings
if isinstance(job['skills'], str):
    job_skills_list = [skill.strip() for skill in job['skills'].split(',')]
else:
    job_skills_list = job['skills']
links_data = collection.query(query_texts=job_skills_list, n_results=2).get('metadatas', [])

# Flatten the list of lists for links_data
flat_links = [item for sublist in links_data for item in sublist]

# Format the links for the email
link_list_formatted = ""
for link_item in flat_links:
    if 'links' in link_item:
        # Assuming the format is "Techstack Link" as seen in the example
        # We need to extract the actual URL
        parts = link_item['links'].split(' ')
        if len(parts) > 1:
            techstack_name = " ".join(parts[:-1]) # Reconstruct techstack name if it has spaces
            url = parts[-1]
            link_list_formatted += f"* {techstack_name}: {url}\n"
        else:
            link_list_formatted += f"* {link_item['links']}\n"


# Define prompt for crafting the email
prompt_email = PromptTemplate.from_template(
    """
    ### JOB DESCRIPTION:
    {job_description}
    
    ### INSTRUCTION:
    You are Shubham Satish Chavan, a job applicant interested in the role mentioned above. You are applying to a company for a position 
    that aligns with your skills and experiences. Write an email expressing your interest in the job, showcasing your background 
    and how your skills can contribute to the company's goals. 
    Mention relevant experiences and achievements that make you a strong candidate for this position. 
    Additionally, include the following links to certifications that demonstrate your proficiency in the skills required for the role:
    {link_list}

    ### CANDIDATE DETAILS:
    - **Name**: Shubham Satish Chavan
    - **Email**: shubhofficial1507@gmail.com
    - **Phone**: (+91) 7666949354
    - **Skills**: Java, Python, C#, C++, MySQL, MS SQL Server, MS Visual Studio, Next.js, HTML, CSS, Javascript, MERN, Flask, Django, Web Development, Android, Desktop App Development, AI, ML, Deep Learning, Teamwork and Collaboration, Leadership and Project Management, Time Management, Good Communication.
    - **Education**:
        - **B.E in Computer Engineering** | Dr. D. Y. Patil Institute of Technology, Pimpri, Pune (Pursuing, Third Year, CGPA: 9.52, 2023-2026).
        - **Diploma in Computer Engineering** | Pimpri Chinchwad Polytechnic, Pune (Final Year Percentage: 91.11%, 2020-2023).
    - **Academic Projects**:
        - **Automated Fracture Detection System**: Developed a machine learning model with 90%+ accuracy for automated fracture detection in X-rays, reducing manual work by 80% and improving diagnostic efficiency by 40%. Role: Developer.
        - **Blog Full Stack Website**: Developed a blog website using the Next.js-enhanced MERN stack, enabling 100+ users for seamless content creation. Role: Developer. Link: [newspiral.vercel.app](http://newspiral.vercel.app).
    - **Position of Responsibility**:
        - **Technical Head** | Dr. D. Y. Patil Institute of Technology (Aug 2024).
    - **Extracurricular / Achievements**:
        - 1st rank in Technical event 
        - IBM Machine Learning Professional Certificate on Coursera (In Progress).
        - Published Research Paper on “ Enhancement of Model Driven Software Development using AI” (IEEE).
        - 3 ongoing Copyrights and Patents.
    - **Social Links**:
        - **GitHub**: [github.com/Shubhamchavan15](https://github.com/Shubhamchavan15)
        - **LinkedIn**: [linkedin.com/in/shubhamchavan15](https://linkedin.com/in/shubhamchavan15)

    Do not provide a preamble.
    ### EMAIL (NO PREAMBLE):
    
    """
)

# Create the email generation chain
chain_email = prompt_email | llm
res = chain_email.invoke({"job_description": str(job), "link_list": link_list_formatted})
print(res.content)
